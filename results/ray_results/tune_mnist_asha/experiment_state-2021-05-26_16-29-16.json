{
  "checkpoints": [
    "{\n  \"trainable_name\": \"training_function\",\n  \"trial_id\": \"bfcc3_00001\",\n  \"config\": {\n    \"layer_1_size\": 32,\n    \"layer_2_size\": 256,\n    \"lr\": 0.0001554534803063829,\n    \"batch_size\": 128,\n    \"mlflow\": {\n      \"experiment_name\": \"/Users/timo.bohnstedt@fau.de/Jiggsaw_test\",\n      \"tracking_uri\": \"databricks\"\n    }\n  },\n  \"local_dir\": \"/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha\",\n  \"evaluated_params\": {\n    \"layer_1_size\": 32,\n    \"layer_2_size\": 256,\n    \"lr\": 0.0001554534803063829,\n    \"batch_size\": 128\n  },\n  \"experiment_tag\": \"1_batch_size=128,layer_1_size=32,layer_2_size=256,lr=0.00015545\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 9,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b098c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"loss\": 0.2734050750732422,\n    \"mean_accuracy\": 0.916796863079071,\n    \"time_this_iter_s\": 7.574472904205322,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 10,\n    \"experiment_id\": \"cd9c2940143c4d1b9df0d8d6742b8d3f\",\n    \"date\": \"2021-05-26_16-33-06\",\n    \"timestamp\": 1622039586,\n    \"time_total_s\": 84.40088295936584,\n    \"pid\": 11955,\n    \"hostname\": \"Timos-MacBook-Pro-2.local\",\n    \"node_ip\": \"192.168.2.103\",\n    \"config\": {\n      \"layer_1_size\": 32,\n      \"layer_2_size\": 256,\n      \"lr\": 0.0001554534803063829,\n      \"batch_size\": 128,\n      \"mlflow\": {\n        \"experiment_name\": \"/Users/timo.bohnstedt@fau.de/Jiggsaw_test\",\n        \"tracking_uri\": \"databricks\"\n      }\n    },\n    \"time_since_restore\": 84.40088295936584,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 10,\n    \"trial_id\": \"bfcc3_00001\",\n    \"experiment_tag\": \"1_batch_size=128,layer_1_size=32,layer_2_size=256,lr=0.00015545\"\n  },\n  \"last_update_time\": 1622039586.557934,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.5499578714370728,\n      \"min\": 0.2734050750732422,\n      \"avg\": 0.34354040026664734,\n      \"last\": 0.2734050750732422,\n      \"last-5-avg\": 0.28742262721061707,\n      \"last-10-avg\": 0.34354040026664734\n    },\n    \"mean_accuracy\": {\n      \"max\": 0.916796863079071,\n      \"min\": 0.8257812261581421,\n      \"avg\": 0.8933203160762787,\n      \"last\": 0.916796863079071,\n      \"last-5-avg\": 0.9118359446525574,\n      \"last-10-avg\": 0.8933203160762787\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16.459539890289307,\n      \"min\": 7.17434024810791,\n      \"avg\": 8.440088295936585,\n      \"last\": 7.574472904205322,\n      \"last-5-avg\": 7.54776439666748,\n      \"last-10-avg\": 8.440088295936585\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"timestamp\": {\n      \"max\": 1622039586,\n      \"min\": 1622039518,\n      \"avg\": 1622039552.0,\n      \"last\": 1622039586,\n      \"last-5-avg\": 1622039570.8,\n      \"last-10-avg\": 1622039552.0\n    },\n    \"time_total_s\": {\n      \"max\": 84.40088295936584,\n      \"min\": 16.459539890289307,\n      \"avg\": 50.483532476425175,\n      \"last\": 84.40088295936584,\n      \"last-5-avg\": 69.30357489585876,\n      \"last-10-avg\": 50.48353247642517\n    },\n    \"pid\": {\n      \"max\": 11955,\n      \"min\": 11955,\n      \"avg\": 11955.0,\n      \"last\": 11955,\n      \"last-5-avg\": 11955.0,\n      \"last-10-avg\": 11955.0\n    },\n    \"time_since_restore\": {\n      \"max\": 84.40088295936584,\n      \"min\": 16.459539890289307,\n      \"avg\": 50.483532476425175,\n      \"last\": 84.40088295936584,\n      \"last-5-avg\": 69.30357489585876,\n      \"last-10-avg\": 50.48353247642517\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"config/layer_1_size\": {\n      \"max\": 32,\n      \"min\": 32,\n      \"avg\": 32.0,\n      \"last\": 32,\n      \"last-5-avg\": 32.0,\n      \"last-10-avg\": 32.0\n    },\n    \"config/layer_2_size\": {\n      \"max\": 256,\n      \"min\": 256,\n      \"avg\": 256.0,\n      \"last\": 256,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"config/lr\": {\n      \"max\": 0.0001554534803063829,\n      \"min\": 0.0001554534803063829,\n      \"avg\": 0.00015545348030638286,\n      \"last\": 0.0001554534803063829,\n      \"last-5-avg\": 0.0001554534803063829,\n      \"last-10-avg\": 0.00015545348030638289\n    },\n    \"config/batch_size\": {\n      \"max\": 128,\n      \"min\": 128,\n      \"avg\": 128.0,\n      \"last\": 128,\n      \"last-5-avg\": 128.0,\n      \"last-10-avg\": 128.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd37e4be0000000473fd2d1d4a0000000473fd24c4640000000473fd1ddcaa0000000473fd17f7800000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe1994140000000473fdb0fbea0000000473fd799f380000000473fd5a73500000000473fd46095c0000000473fd37e4be0000000473fd2d1d4a0000000473fd24c4640000000473fd1ddcaa0000000473fd17f7800000000652e\"\n      }\n    },\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fecf33340000000473fed2199a0000000473fed300000000000473fed4999a0000000473fed566660000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fea6cccc0000000473febce6660000000473fec4e6660000000473fec9b3340000000473fecd33340000000473fecf33340000000473fed2199a0000000473fed300000000000473fed4999a0000000473fed566660000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401e1e0fd000000047401e8e568000000047401dc0d7d000000047401e3b0d0000000047401e4c42a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403075a46800000047401fdf1dd000000047401cb2864000000047401e4271f000000047401dfb4bb000000047401e1e0fd000000047401e8e568000000047401dc0d7d000000047401e3b0d0000000047401e4c42a0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a045cae604a0b5cae604a135cae604a1a5cae604a225cae60652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284ade5bae604ae65bae604aed5bae604af55bae604afc5bae604a045cae604a0b5cae604a135cae604a1a5cae604a225cae60652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b18806400000047404eea4b3400000047405151331700000047405334e3e700000047405519a811000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403075a4680000004740386d6bdc00000047403f9a0d6c0000004740439554f400000047404754be6a00000047404b18806400000047404eea4b3400000047405151331700000047405334e3e700000047405519a811000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db32e4db32e4db32e4db32e4db32e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284db32e4db32e4db32e4db32e4db32e4db32e4db32e4db32e4db32e4db32e652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b18806400000047404eea4b3400000047405151331700000047405334e3e700000047405519a811000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403075a4680000004740386d6bdc00000047403f9a0d6c0000004740439554f400000047404754be6a00000047404b18806400000047404eea4b3400000047405151331700000047405334e3e700000047405519a811000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"config/layer_1_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b204b204b204b204b20652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b204b204b204b204b204b204b204b204b204b20652e\"\n      }\n    },\n    \"config/layer_2_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d00014d00014d00014d00014d0001652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00014d00014d00014d00014d00014d00014d00014d00014d00014d0001652e\"\n      }\n    },\n    \"config/lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb473f2460273a59a8bb652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b804b804b804b804b80652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b804b804b804b804b804b804b804b804b804b80652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1622039498.6785438,\n  \"logdir\": \"/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha/training_function_bfcc3_00001_1_batch_size=128,layer_1_size=32,layer_2_size=256,lr=0.00015545_2021-05-26_16-29-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"training_function\",\n  \"trial_id\": \"bfcc3_00000\",\n  \"config\": {\n    \"layer_1_size\": 128,\n    \"layer_2_size\": 256,\n    \"lr\": 0.0031354923020492954,\n    \"batch_size\": 128,\n    \"mlflow\": {\n      \"experiment_name\": \"/Users/timo.bohnstedt@fau.de/Jiggsaw_test\",\n      \"tracking_uri\": \"databricks\"\n    }\n  },\n  \"local_dir\": \"/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha\",\n  \"evaluated_params\": {\n    \"layer_1_size\": 128,\n    \"layer_2_size\": 256,\n    \"lr\": 0.0031354923020492954,\n    \"batch_size\": 128\n  },\n  \"experiment_tag\": \"0_batch_size=128,layer_1_size=128,layer_2_size=256,lr=0.0031355\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 9,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b2000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944b098c03475055944b008c066d656d6f7279944b008c136f626a6563745f73746f72655f6d656d6f7279944b0075618c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"last_result\": {\n    \"loss\": 0.30423396825790405,\n    \"mean_accuracy\": 0.9501953125,\n    \"time_this_iter_s\": 8.09816598892212,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 10,\n    \"experiment_id\": \"d93fe6d845da42279704860fb38352a3\",\n    \"date\": \"2021-05-26_16-30-47\",\n    \"timestamp\": 1622039447,\n    \"time_total_s\": 87.86598896980286,\n    \"pid\": 11966,\n    \"hostname\": \"Timos-MacBook-Pro-2.local\",\n    \"node_ip\": \"192.168.2.103\",\n    \"config\": {\n      \"layer_1_size\": 128,\n      \"layer_2_size\": 256,\n      \"lr\": 0.0031354923020492954,\n      \"batch_size\": 128,\n      \"mlflow\": {\n        \"experiment_name\": \"/Users/timo.bohnstedt@fau.de/Jiggsaw_test\",\n        \"tracking_uri\": \"databricks\"\n      }\n    },\n    \"time_since_restore\": 87.86598896980286,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 10,\n    \"trial_id\": \"bfcc3_00000\",\n    \"experiment_tag\": \"0_batch_size=128,layer_1_size=128,layer_2_size=256,lr=0.0031355\"\n  },\n  \"last_update_time\": 1622039447.306908,\n  \"metric_analysis\": {\n    \"loss\": {\n      \"max\": 0.31648510694503784,\n      \"min\": 0.1946648210287094,\n      \"avg\": 0.25504791736602783,\n      \"last\": 0.30423396825790405,\n      \"last-5-avg\": 0.29459403157234193,\n      \"last-10-avg\": 0.25504791736602783\n    },\n    \"mean_accuracy\": {\n      \"max\": 0.9537109136581421,\n      \"min\": 0.9345703125,\n      \"avg\": 0.9470507800579071,\n      \"last\": 0.9501953125,\n      \"last-5-avg\": 0.9499609351158143,\n      \"last-10-avg\": 0.9470507800579071\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16.851111888885498,\n      \"min\": 7.78428316116333,\n      \"avg\": 8.786598896980285,\n      \"last\": 8.09816598892212,\n      \"last-5-avg\": 7.939737987518311,\n      \"last-10-avg\": 8.786598896980285\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"timestamp\": {\n      \"max\": 1622039447,\n      \"min\": 1622039376,\n      \"avg\": 1622039411.2999997,\n      \"last\": 1622039447,\n      \"last-5-avg\": 1622039431.0,\n      \"last-10-avg\": 1622039411.3\n    },\n    \"time_total_s\": {\n      \"max\": 87.86598896980286,\n      \"min\": 16.851111888885498,\n      \"avg\": 52.19959027767182,\n      \"last\": 87.86598896980286,\n      \"last-5-avg\": 71.86103038787842,\n      \"last-10-avg\": 52.19959027767182\n    },\n    \"pid\": {\n      \"max\": 11966,\n      \"min\": 11966,\n      \"avg\": 11966.0,\n      \"last\": 11966,\n      \"last-5-avg\": 11966.0,\n      \"last-10-avg\": 11966.0\n    },\n    \"time_since_restore\": {\n      \"max\": 87.86598896980286,\n      \"min\": 16.851111888885498,\n      \"avg\": 52.19959027767182,\n      \"last\": 87.86598896980286,\n      \"last-5-avg\": 71.86103038787842,\n      \"last-10-avg\": 52.19959027767182\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 10,\n      \"min\": 1,\n      \"avg\": 5.5,\n      \"last\": 10,\n      \"last-5-avg\": 8.0,\n      \"last-10-avg\": 5.5\n    },\n    \"config/layer_1_size\": {\n      \"max\": 128,\n      \"min\": 128,\n      \"avg\": 128.0,\n      \"last\": 128,\n      \"last-5-avg\": 128.0,\n      \"last-10-avg\": 128.0\n    },\n    \"config/layer_2_size\": {\n      \"max\": 256,\n      \"min\": 256,\n      \"avg\": 256.0,\n      \"last\": 256,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"config/lr\": {\n      \"max\": 0.0031354923020492954,\n      \"min\": 0.0031354923020492954,\n      \"avg\": 0.0031354923020492954,\n      \"last\": 0.0031354923020492954,\n      \"last-5-avg\": 0.0031354923020492954,\n      \"last-10-avg\": 0.0031354923020492954\n    },\n    \"config/batch_size\": {\n      \"max\": 128,\n      \"min\": 128,\n      \"avg\": 128.0,\n      \"last\": 128,\n      \"last-5-avg\": 128.0,\n      \"last-10-avg\": 128.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3487200000000473fd1680ec0000000473fd4414ac0000000473fd1dac760000000473fd37891c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fca9804c0000000473fc8eac6e0000000473fcd11cc40000000473fccea5fa0000000473fcc6cd940000000473fd3487200000000473fd1680ec0000000473fd4414ac0000000473fd1dac760000000473fd37891c0000000652e\"\n      }\n    },\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fee600000000000473fee5b3340000000473fee566660000000473fee84ccc0000000473fee680000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fede80000000000473fee380000000000473fee1b3340000000473fee54ccc0000000473fee800000000000473fee600000000000473fee5b3340000000473fee566660000000473fee84ccc0000000473fee680000000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401f4dd6a000000047401f88498000000047401fb36b9000000047401fdd64100000004740203242d0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030d9e27800000047401f5f384000000047401f9ac05000000047401f26b2e000000047401f231b2000000047401f4dd6a000000047401f88498000000047401fb36b9000000047401fdd64100000004740203242d0000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"timestamp\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a775bae604a7f5bae604a875bae604a8f5bae604a975bae60652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a505bae604a585bae604a605bae604a675bae604a6f5bae604a775bae604a7f5bae604a875bae604a8f5bae604a975bae60652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bff24e200000047404ff02e12000000474051f34dc2000000474053f12403000000474055f76c5d000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030d9e278000000474038b1b0880000004740404c304e0000004740443106aa000000474048156a0e00000047404bff24e200000047404ff02e12000000474051f34dc2000000474053f12403000000474055f76c5d000000652e\"\n      }\n    },\n    \"pid\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dbe2e4dbe2e4dbe2e4dbe2e4dbe2e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dbe2e4dbe2e4dbe2e4dbe2e4dbe2e4dbe2e4dbe2e4dbe2e4dbe2e4dbe2e652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404bff24e200000047404ff02e12000000474051f34dc2000000474053f12403000000474055f76c5d000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030d9e278000000474038b1b0880000004740404c304e0000004740443106aa000000474048156a0e00000047404bff24e200000047404ff02e12000000474051f34dc2000000474053f12403000000474055f76c5d000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b0a652e\"\n      }\n    },\n    \"config/layer_1_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b804b804b804b804b80652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b804b804b804b804b804b804b804b804b804b80652e\"\n      }\n    },\n    \"config/layer_2_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d00014d00014d00014d00014d0001652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00014d00014d00014d00014d00014d00014d00014d00014d00014d0001652e\"\n      }\n    },\n    \"config/lr\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888473f69af9a9c9cf888652e\"\n      }\n    },\n    \"config/batch_size\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b804b804b804b804b80652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b804b804b804b804b804b804b804b804b804b80652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1622039356.208249,\n  \"logdir\": \"/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha/training_function_bfcc3_00000_0_batch_size=128,layer_1_size=128,layer_2_size=256,lr=0.0031355_2021-05-26_16-29-16\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 1000,
    "_metric": "loss",
    "_total_time": 187.93951082229614,
    "_iteration": 127,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1622039356.07697,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2021-05-26_16-29-16",
    "checkpoint_file": "/Users/beantown/PycharmProjects/jigsaw-puzzle-solver/results/ray_results/tune_mnist_asha/experiment_state-2021-05-26_16-29-16.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1622039356.07697,
    "timestamp": 1622039636.540266
  }
}